{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaaf1c34",
   "metadata": {},
   "source": [
    "\n",
    "# Capítulo 4 — Aprendizado Supervisionado (Classificação)\n",
    "\n",
    "**Curso:** CECIERJ – IA e ML para Soluções Práticas  \n",
    "**Objetivo:** aplicar algoritmos de classificação supervisionada com Scikit-learn, avaliando desempenho com métricas adequadas.\n",
    "\n",
    "---\n",
    "## Passos abordados\n",
    "1. Carregar dataset (Breast Cancer).  \n",
    "2. *Train/Test Split*.  \n",
    "3. Treinar modelos: **Logistic Regression, KNN, Decision Tree, SVM**.  \n",
    "4. Avaliar com métricas (accuracy, precision, recall, F1, ROC AUC).  \n",
    "5. Comparar resultados em DataFrame.  \n",
    "6. Ajustar hiperparâmetros com `GridSearchCV`.  \n",
    "7. Visualizações: matriz de confusão, curva ROC.  \n",
    "8. Conclusões sobre trade-offs dos modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "ds = load_breast_cancer(as_frame=True)\n",
    "df = ds.frame.copy()\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "print(\"Shape:\", X.shape, \"Target balance:\", y.value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": Pipeline([(\"scaler\", StandardScaler()), (\"clf\", LogisticRegression(max_iter=1000))]),\n",
    "    \"KNN\": Pipeline([(\"scaler\", StandardScaler()), (\"clf\", KNeighborsClassifier())]),\n",
    "    \"Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"SVM\": Pipeline([(\"scaler\", StandardScaler()), (\"clf\", SVC(probability=True))]),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model,\"predict_proba\") else None\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    results[name] = dict(accuracy=acc, precision=prec, recall=rec, f1=f1, roc_auc=auc)\n",
    "\n",
    "pd.DataFrame(results).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.1, 1, 10],\n",
    "    \"clf__kernel\": [\"linear\",\"rbf\"],\n",
    "    \"clf__gamma\": [\"scale\", 0.01]\n",
    "}\n",
    "svm_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", SVC(probability=True))])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gs = GridSearchCV(svm_pipe, param_grid, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Melhores params SVM:\", gs.best_params_, \"ROC AUC:\", gs.best_score_)\n",
    "best_svm = gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe00884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = best_svm.predict(X_test)\n",
    "y_proba = best_svm.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()\n",
    "plt.title(\"Matriz de Confusão (SVM otimizado)\")\n",
    "plt.show()\n",
    "\n",
    "RocCurveDisplay.from_estimator(best_svm, X_test, y_test)\n",
    "plt.title(\"Curva ROC (SVM otimizado)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d92c4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Conclusões\n",
    "- Modelos lineares (LogReg) são simples e eficientes, boa baseline.  \n",
    "- KNN sensível à escala → normalize sempre.  \n",
    "- Árvores capturam não linearidades, mas podem sobreajustar.  \n",
    "- SVM com tuning pode atingir maior ROC AUC.  \n",
    "- Escolha depende de trade-off entre interpretabilidade, custo e métrica-alvo.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
