{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a46c346",
   "metadata": {},
   "source": [
    "\n",
    "# Capítulo 6 — Avaliação de Modelos\n",
    "\n",
    "**Curso:** CECIERJ – IA e ML para Soluções Práticas  \n",
    "**Objetivo:** comparar diferentes estratégias de avaliação, entender *bias/variance* e inspecionar curvas de aprendizado e calibração de probabilidades.\n",
    "\n",
    "---\n",
    "## Passos abordados\n",
    "1. Conceito de **holdout vs cross-validation**.  \n",
    "2. Uso de **K-Fold/StratifiedKFold**.  \n",
    "3. **Learning Curves** para diagnosticar *overfitting/underfitting*.  \n",
    "4. **Validation Curves** para hiperparâmetros.  \n",
    "5. **Calibration Curve** para probabilidades.  \n",
    "6. Interpretação prática dos gráficos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e64904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ds = load_breast_cancer()\n",
    "X, y = ds.data, ds.target\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", LogisticRegression(max_iter=1000, random_state=42))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff563bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Holdout simples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Accuracy holdout:\", pipe.score(X_test, y_test))\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"accuracy\")\n",
    "print(\"CV média:\", scores.mean(), \"Desvio:\", scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    pipe, X, y, cv=cv, scoring=\"accuracy\", train_sizes=np.linspace(0.1,1.0,5), n_jobs=-1\n",
    ")\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), 'o-', label=\"Treino\")\n",
    "plt.plot(train_sizes, val_scores.mean(axis=1), 's-', label=\"Validação\")\n",
    "plt.xlabel(\"Tamanho do treino\"); plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Learning Curve (LogReg)\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = [0.01, 0.1, 1, 10, 100]\n",
    "train_scores, val_scores = validation_curve(\n",
    "    pipe, X, y, param_name=\"clf__C\", param_range=param_range,\n",
    "    cv=cv, scoring=\"accuracy\", n_jobs=-1\n",
    ")\n",
    "plt.figure()\n",
    "plt.semilogx(param_range, train_scores.mean(axis=1), 'o-', label=\"Treino\")\n",
    "plt.semilogx(param_range, val_scores.mean(axis=1), 's-', label=\"Validação\")\n",
    "plt.xlabel(\"Parâmetro C (LogReg)\"); plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "disp = CalibrationDisplay.from_estimator(pipe, X_test, y_test, n_bins=10)\n",
    "disp.ax_.set_title(\"Calibration Curve (LogReg)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884f515",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Conclusões\n",
    "- **Holdout** é rápido, mas pode variar; **Cross-validation** dá média mais estável.  \n",
    "- **Learning curve** ajuda a diagnosticar se há *underfitting* (treino/validação baixos) ou *overfitting* (gap alto).  \n",
    "- **Validation curve** mostra sensibilidade a hiperparâmetros.  \n",
    "- **Calibration curve** avalia se probabilidades estão bem calibradas (importante em risco/saúde).  \n",
    "- Combine métricas + curvas para decidir ajustes de modelo.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
