{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a852c9d",
   "metadata": {},
   "source": [
    "\n",
    "# Capítulo 9 — Ética, Governança e Futuro da IA\n",
    "\n",
    "**Curso:** CECIERJ – IA e ML para Soluções Práticas  \n",
    "**Objetivo:** discutir aspectos éticos, legais e de governança no uso da IA, e refletir sobre tendências futuras.\n",
    "\n",
    "---\n",
    "## Temas principais\n",
    "1. **Viés e justiça**: modelos podem reproduzir/prejudicar grupos se dados de treino são enviesados.  \n",
    "2. **Privacidade e LGPD**: respeitar finalidade, consentimento e minimização de dados.  \n",
    "3. **Transparência e explicabilidade**: stakeholders precisam entender como decisões são tomadas.  \n",
    "4. **Reprodutibilidade**: garantir que resultados possam ser reproduzidos (seeds, versões, lineage).  \n",
    "5. **Segurança e robustez**: prevenir ataques adversariais, falhas críticas e mau uso.  \n",
    "6. **Governança e monitoramento**: acompanhar métricas, drifts e impacto social.  \n",
    "7. **Futuro da IA**: integração com saúde, educação, sustentabilidade; avanços em IA generativa e RL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f691ec",
   "metadata": {},
   "source": [
    "\n",
    "## Checklist Ético para Projetos de IA\n",
    "Use esta lista em cada entrega de projeto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checklist = [\n",
    "    \"Dados coletados têm base legal (LGPD) e consentimento informado?\",\n",
    "    \"O dataset foi auditado para viés e representatividade?\",\n",
    "    \"A métrica escolhida reflete o impacto no negócio e na sociedade?\",\n",
    "    \"Foi avaliada a interpretabilidade do modelo (SHAP, LIME etc.)?\",\n",
    "    \"Reprodutibilidade: seeds, versões de libs, dataset e código documentados?\",\n",
    "    \"Plano de monitoramento em produção (drift, fairness, desempenho)?\",\n",
    "    \"Plano de rollback em caso de falha?\",\n",
    "    \"Stakeholders foram informados de riscos e limitações?\",\n",
    "]\n",
    "for item in checklist:\n",
    "    print(\"✔\", item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a5db3",
   "metadata": {},
   "source": [
    "\n",
    "## Ferramentas e boas práticas\n",
    "- **Auditoria de viés**: AIF360, Fairlearn.  \n",
    "- **Explicabilidade**: LIME, SHAP, ELI5.  \n",
    "- **Gestão de modelos**: MLflow, DVC, MLOps pipelines.  \n",
    "- **Segurança**: anonimização, differential privacy, testes adversariais.  \n",
    "- **Governança**: políticas claras de acesso, logs de uso, comitês éticos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86220c",
   "metadata": {},
   "source": [
    "\n",
    "## Tendências futuras\n",
    "- IA Generativa (texto, imagem, código) aplicada em educação, saúde, arte.  \n",
    "- Aprendizado por Reforço em sistemas complexos (robôs, logística, energia).  \n",
    "- Modelos multimodais (texto+imagem+áudio).  \n",
    "- Sustentabilidade: IA para eficiência energética e clima.  \n",
    "- Regulações mais robustas (UE AI Act, leis nacionais).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560bec5d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Conclusões\n",
    "- Ética em IA não é opcional, é parte essencial do ciclo de vida do modelo.  \n",
    "- Projetos devem considerar **impacto social** além de métricas técnicas.  \n",
    "- O futuro da IA exige **responsabilidade, governança e interdisciplinaridade**.  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
