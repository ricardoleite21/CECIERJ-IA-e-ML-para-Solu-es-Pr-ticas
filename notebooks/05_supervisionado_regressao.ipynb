{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3b27dd",
   "metadata": {},
   "source": [
    "\n",
    "# Capítulo 5 — Aprendizado Supervisionado (Regressão)\n",
    "\n",
    "**Curso:** CECIERJ – IA e ML para Soluções Práticas  \n",
    "**Objetivo:** prever variáveis contínuas (ex.: preço, tempo) e avaliar modelos de regressão com métricas adequadas.\n",
    "\n",
    "---\n",
    "## Passos abordados\n",
    "1. Carregar dataset (Diabetes).  \n",
    "2. *Train/Test Split*.  \n",
    "3. Baseline (média).  \n",
    "4. Modelos: **Linear, Ridge, Lasso, RandomForest**.  \n",
    "5. Métricas: **MAE, MSE, RMSE, R²**.  \n",
    "6. `GridSearchCV` para RandomForest.  \n",
    "7. Importância de atributos (`permutation_importance`).  \n",
    "8. Salvar o melhor modelo (`joblib`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb473796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "ds = load_diabetes()\n",
    "X = pd.DataFrame(ds.data, columns=ds.feature_names)\n",
    "y = pd.Series(ds.target, name=\"target\")\n",
    "print(\"Shape:\", X.shape)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e70e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def report(y_true, y_pred, label):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{label:12s} | MAE={mae:.3f} | MSE={mse:.1f} | RMSE={rmse:.3f} | R2={r2:.3f}\")\n",
    "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "baseline_pred = np.repeat(y_train.mean(), len(y_test))\n",
    "baseline = report(y_test, baseline_pred, \"Baseline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "candidates = {\n",
    "    \"Linear\": Pipeline([(\"scaler\", StandardScaler()), (\"mdl\", LinearRegression())]),\n",
    "    \"Ridge\":  Pipeline([(\"scaler\", StandardScaler()), (\"mdl\", Ridge())]),\n",
    "    \"Lasso\":  Pipeline([(\"scaler\", StandardScaler()), (\"mdl\", Lasso(max_iter=5000))]),\n",
    "    \"RF\":     Pipeline([(\"mdl\", RandomForestRegressor(random_state=42))]),\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "for name, pipe in candidates.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    metrics[name] = report(y_test, pred, name)\n",
    "\n",
    "pd.DataFrame(metrics).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {\n",
    "    \"mdl__n_estimators\": [100, 300],\n",
    "    \"mdl__max_depth\": [None, 10, 20],\n",
    "    \"mdl__min_samples_split\": [2, 5]\n",
    "}\n",
    "gs = GridSearchCV(\n",
    "    candidates[\"RF\"], grid, scoring=\"neg_root_mean_squared_error\", cv=5, n_jobs=-1\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Melhores hiperparâmetros RF:\", gs.best_params_)\n",
    "best_rf = gs.best_estimator_\n",
    "pred = best_rf.predict(X_test)\n",
    "best_metrics = report(y_test, pred, \"RF tuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "r = permutation_importance(best_rf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "imp = pd.Series(r.importances_mean, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure()\n",
    "imp.head(10).plot(kind=\"bar\")\n",
    "plt.title(\"Importância de atributos (Permutation) — Top 10\")\n",
    "plt.xlabel(\"Atributo\"); plt.ylabel(\"Importância média\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib, os\n",
    "save_path = \"/mnt/data/modelo_cap5_rf_tuned.joblib\"\n",
    "joblib.dump(best_rf, save_path)\n",
    "print(\"Modelo salvo em:\", save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e0590",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Conclusões\n",
    "- **Linear/Ridge/Lasso**: simples, rápidos e interpretáveis (atenção ao *scaling*).  \n",
    "- **RandomForest**: captura relações não lineares; *tuning* melhora muito o RMSE.  \n",
    "- Compare sempre com **baseline**; olhe **MAE, RMSE e R²**.  \n",
    "- Use **permutation importance** para explicar variáveis relevantes.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
